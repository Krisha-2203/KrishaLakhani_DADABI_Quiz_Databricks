{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0df76f83-e156-44e7-9ea6-3286c70d224a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <html>\n",
       "      <div style=\"font-size:18px\">\n",
       "        The Delta Live Tables (DLT) module is not supported on this cluster.\n",
       "        You should either <a href=\"?o=4065629032716591#joblist/pipelines/create?initialSource=%2FUsers%2Flakhani.kri%40northeastern.edu%2FMaterial_Master_DLT%2FMaterialMaster_bronze&redirectNotebookId=2002603281144297\">create a new pipeline</a> or use an existing pipeline to run DLT code.\n",
       "      </div>\n",
       "    </html>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-6823359354773124>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdlt\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functions \u001B[38;5;28;01mas\u001B[39;00m F\n",
       "\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dlt'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ModuleNotFoundError",
        "evalue": "No module named 'dlt'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'dlt'"
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "NOTEBOOK_USER_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KD00G",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
        "File \u001B[0;32m<command-6823359354773124>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdlt\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functions \u001B[38;5;28;01mas\u001B[39;00m F\n",
        "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dlt'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b69ed793-044a-4e22-b76c-9d8844494c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"BRONZE\",\n",
    "    comment=\"Raw pipe-delimited data loaded into the Bronze layer.\"\n",
    ")\n",
    "def bronze_load():\n",
    "    df = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"delimiter\", \"|\")        # Pipe-delimited CSV\n",
    "        .option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .load(\"/Volumes/workspace/damg7370/datastore/material_master_1k.csv\")\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57622902-b9ee-44d6-a8c7-5328fddbb92b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, trim, current_timestamp\n",
    "\n",
    "@dlt.expect_or_drop(\"valid_cost\", \"unit_cost > 0\")  # Drop invalid cost rows\n",
    "@dlt.expect(\"valid_lead_time\", \"lead_time_days >= 0\")\n",
    "@dlt.expect(\"valid_safety_stock\", \"safety_stock >= 0\")\n",
    "@dlt.table(\n",
    "    name=\"SILVER\",\n",
    "    comment=\"Single Silver layer â€” cleaned, standardized, and validated material master data.\"\n",
    ")\n",
    "def silver_material_master():\n",
    "    # Read data from Bronze layer\n",
    "    df = dlt.read(\"BRONZE\")\n",
    "\n",
    "    # Trim whitespace from all string columns\n",
    "    df = df.select([trim(col(c)).alias(c) for c in df.columns])\n",
    "\n",
    "    # Drop records with null critical fields\n",
    "    df = df.dropna(subset=[\"material_id\", \"material_name\"])\n",
    "\n",
    "    # Convert datatypes for numeric columns\n",
    "    df = (\n",
    "        df.withColumn(\"unit_cost\", col(\"unit_cost\").cast(\"double\"))\n",
    "          .withColumn(\"lead_time_days\", col(\"lead_time_days\").cast(\"int\"))\n",
    "          .withColumn(\"safety_stock\", col(\"safety_stock\").cast(\"int\"))\n",
    "          .withColumn(\"reorder_level\", col(\"reorder_level\").cast(\"int\"))\n",
    "          .withColumn(\"load_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "    # Return cleaned and validated dataframe\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MaterialMaster_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}